--update blogpost on number theory + combinatorics
These math subdomains would remain obscure if programming as a profession were not this popular, wide spread, lucrative and economically important.

Since the 2000's, more and more IV focus is placed on math, largely in these two subdomains.

This trend is bad news for the GTD types like Ashish/CSY, the domain experts and the managers like Shuo etc

--new  : linkedHashSet as dynamic sorted collection with O(1) remove but without insert. Not available in other languages.

--new: java ref closest cousin]]c++: pointer!!ref
java (and c#) reference varialbes are more like pointer variables than c++ reference variables
c++ reference variables can't be reseated. This is the major difference.

--why can't we take the address of a c++ reference variable? 
A pointer is conceptually a runtime object, occupying run time memory, with an address.

A ref is strictly a variable and never a runtime object, so it has no address at runtime. I suspect compiler replaces it with the target variable.

--new: competitors to x86 instruction sets
Interviewers often focus on x86 instruction sets, but I could point out competing instruction sets.

IBM's PowerPC and Oracle's Sparc, were once popular instruction sets in HighPerformanceComputing. Even if they are less popular now, the still have a presence.

AMD64 instruction set (i.e. x86-64) was created at AMD, as an extension on x86

IA-64 instruction set was created at HP then Intel, widely deployed in data centers.

If interivew is not 100% focused on server-side, then I would point out ARM instruction set is dominant in handheld.

--update blogpost on Optional.java
https://dzone.com/articles/considerations-when-returning-java-8s-optional-from-a-method shows the pitfalls of returning Optional from a method.

I feel this is like borrowing from a loan shark to avoid accidental credit card interest charge. 

If you are careful, it can help you avoid the NPE of the traditional practice, but if you are undisciplined (like most of us), then this new stragey is even worse -- 

Traditional return type is something like String, but caller has to deal with nulls. New strategy is supposed to remove the risk/doubt of a null return value, but alas, caller still needs to check null first, before checking against empty!

--new:
For c++ to hold its ground in the latency benchmarks
* no new no malloc. Use stack and data segment
* no STL no std::string no shared_ptr
* optimize d-cache and i-cache
* use compile-time programming

For java, 
* no GC

--new or update blogpost: advantage of make_shared
* one allocation fewer. I think one allocation is thousands of times slower than a simple calc
* code size is smaller and more i-cache friendly

--threading is a core IV topic in java, but remain a "superstructure" topic in c++, in the form of c++11 thread and pthreads.

I think java threading is simpler and accessible to regular app developers whereas c++ threading remains part of the vast array of advanced topics.

I think my progress in my c++ QQ performance since 2011 was mostly in the core QQ topics. I achieved some thick->thin and critical mass.

--really low-latency apps should probably avoid lock-free... Strictly single-threaded mode, strictly. 

--fuxi: mlphone bb app settings
in any bb app, hit the bb icon at bottom right -> hit gear icon on bottom left -> per-app settings

--sugg: q[ nn ] and q[ commit --amend ] both to detect the current HEAD is also origin/.... Use commit hook

--fuxi: cpu set seems to be a linux feature, not just a container feature

--new: cpu affinity
sched_setaffinity is a syscall!
all other *affinity* functions are based thereon

*_np in function name means non-portable

Need to read more. Similar to socket QQ -- Not deep, but even more academic than socket

--new:
is malloc a kernel service, syscall or a userland function offered in a regular library?

Can I implement my own DAM without involving the kernel?

--Martin's low-latency java talk
Deallocation is worse than allocation. Deallocation may use locking if performed across threads.

My Questions
Q: for low latency should we avoid concurrency ?
A: yes
%%A: parallel processing in ST-Mode is good but avoid any form of synchronization 

Q: If I don’t use heap, and only use stack and static memory….?
A: heap allows sharing between threads

Q: why is JIT not available to c++?

--pointer as a field of a class is uninitialized by default
I think Ashish's test shows it

However, such a field creates an opportunity for mv-ctor. The referent object is usually on heap on in static memory

--fuxi: Q: why unlike java/c#, in my c++ jobs I seldom needed to learn ide? 
(I used msvs only for automated build since windows command line build is based on msvs.)

in my java jobs, i often need to spend lots of time learning the ide features.

A: c++ IDE is less effective less value-adding more complicated. Majority of c++ developers actually don't use any IDE. 

--new: 
one of the most obvious and real limitation/obsolete features of c++ as a language is the tool chain.
Part of the ecosystem
Too complicated compared to newer languages like java. The dynamic scripting languages are even simpler

Also an entry barrier. Young people can take it up if determined, but majority of them are put off. 

There's a minimum mileage required. Many young people don't stay on it long enough. 

My vi mileage is also too short.

In my early days using c++, I tried to set up eclipse CDT and spent lots of time on the tool chain. My goal was to set up similar convenience ... Futile. Not worthwhile. java tools are much better. Most c++ programmers don't bother with such convenience and rely on command line tools.

Similarly, yoga is hard for most people but some individuals are determined and can overcome the initial hump (6-24M) and find joy and reward

--new: low latency: avoid dynamic data structures
RTS uses no STL containers.

In my first programing job, I used C without malloc, because I used only array + struct. If my collection were to grow, then I would have needed DAM. 

I feel low latency generally avoid mid-day DAM. If DAM required, then pre-allocation is preferred.

--GS-HK interviewer said with an array-based order book he could achieve 1 million updates per second.

This is in response to my claim that Rebus is 700K MPS, which is not far behind. No shame -- 
Martin Thompson basically said if the performance is good enough for the requirement, then no need to go further.

--new: bcomp advantage over git-diff
* shows byte count in new vs old versions, useful in git blogging intra moves
* can hide minor changes
* shows char-level changes -- hard to see in git-diff

--fuxi: C continues to dominates in system programming
low-latency
sys calls
socket programming
pthreads

--fuxi: microsoft acquired Mono project and produced dotnet core (Sunil) as a jvm challenger to run on non-windows platforms

--fuxi: java community support is better than c# or c++
higher collective brain power
