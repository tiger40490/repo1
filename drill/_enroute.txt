[c=classic]
[e=ez]
[L=leetcode]
[v=easy to verify]
 
====Q [L547] union-find problem: 
There are N students in a class. Some of them are friends, while some are not. If A is a direct friend of B, and B is a direct friend of C, then A is an indirect friend of C. And we defined a friend circle is a group of students who are direct or indirect friends.

Given a N*N matrix M representing the friend relationship between students in the class. If M[i][j] = 1, then the ith and jth students are direct friends with each other, otherwise not. And you have to output the total number of friend circles among all the students.

--analysis:
assign unique id to each circle. Challenge is merge.

Rated "medium" on leetcode but clearly easier than many "easy" questions. Clearly this is a data-structure question ... my traditional stronghold.

--design 1:
Circle class{ circleId, vector(presized) of studentId}
map{studentId -> circleId}

When we merge two circles, the smaller circle's students would update their circuleId. Iterative over all students in that small circle

--design 2:
Same map, but Circle class is now {circleId, parentCircleId (default -1)}
The acquired circle will have this field set to a top-level circleId... Path compression as in disjoint set. 
The merge would only update this one field in one object.

Scenario:
circles AA, BB, CC created
circle a2 acquired by AA
circle a3 acquired by a2 (branded by AA)
circle b2 acquired by BB
a2 and b2 are now merged --> need to update BB as acquired, but do we have to update b2? Suppose I don't.
circle c2 acquired by CC
c2 now merging with b2. Now c2 will get branded by AA, and so should the nodes on the path (c2 -> b2 -> BB -> AA) This would speed up future mergers.

* additional field: The vector of studentId is needed only if we need to output the individual students in each circle.

After the data structures are updated, we iterate over all circle objects. Return the top-level circles.

====Q [L127] word ladder
Given two words (beginWord and endWord), and a dictionary's word list, find the length of shortest transformation sequence from beginWord to endWord, such that:

* Only one letter can be changed at a time.
* Each transformed word must exist in the word list. Note that beginWord is not a transformed word.
* Return 0 if there is no such transformation sequence.
* All words have the same length.
* All words contain only lowercase alphabetic characters.
* You may assume no duplicates in the word list.
Example 1:
beginWord = "hit",
endWord = "cog",
wordList = ["hot","dot","dog","lot","log","cog"]
Output: 5
Explanation: As one shortest transformation is "hit" -> "hot" -> "dot" -> "dog" -> "cog",
return its length 5.

Example 2:
beginWord = "hit"
endWord = "cog"
wordList = ["hot","dot","dog","lot","log"]
Output: 0

--analysis: 
First scan O(NN)to build the graph. Given an existing graph of N words (N can be 1), a new word is compared to each to construct the edge list.

2nd scan O(N+E) BFT

====Q [c DP] given the first N natural numbers, how many BST can you form?
how do you make use of the previous results for N=2 to tackle N=3?
N=2: ans=2
N=3: need to draw them to see patterns

====Q [c str] longest palindrome subsequence (not subarray)
if there's an elegant idea then I should try then read it. 

To keep things simple just assume there are only 3 unique chars

Can we safely remove some char to reduce the problem to a smaller problem?

--DP idea
as we increment a forward marker, we keep all growers.

Each grower keeps a hashtable (or array) of unused chars on its left. Each entry is {unused char -> sorted stack of positions}

As we increment the iterator, we first grow the leading pack of longest growers. In fact, I might pick one grower only [1]. IIF all of them stop growing, then we look at the next pack of next-longest prowers.

[1] I pick the lowest Member.ri value

grower is kinda immutable. Always clones itself before it grows.

If this works it is again using auxDS, my strength

====Q[c e v] implement half-written abbr_iterative.h based on the abbr_ascendRecursive.h
Not so easy when the word contains dupe letters. I think hashtable is simplest solution in a realistic context, as explained in cookbook.py
