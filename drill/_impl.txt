====Q [c DP] rod-cutting problem (from Rahul, simpler than knapsack problem): Given a single rod of 10m, also given a price table for pieces like 2m, 5m etc, optimize for total value. A stub (too small) is worthless.

f(remainingLen) is the memoization function to write.

Always start with pieces of highest density (:=price/len)...

"Formula" means something like 2+2+3+5. Should be sorted by density.

As soon we get no stub, we found the optimal "formula"... game over
--can we reduce recursion depth if we keep cutting in a while loop?
====Q [c DP] knapsack problem: we are given a fixed set of n items, where each item i is specified by a size s[i] and a value v[i]. 
We are also given a size bound S (the size of our knapsack). 
The optimization goal is to find the subset of items of maximum total value such that sum of their sizes is at most S (they all fit into the knapsack)

(A minor variation -- minimum size for a total value up to V)

Different from rod-cutting -- can't create multiple clones of item3

classic memoization-DP problem. I think there's recursion in a loop.
f(remainingItems, remainingCapacity) is the basic function to write.

I would want to sort the items by "density" of value, so i always take the densest item unless it doesn't fit

Forget about bottom-up. First get the top-down to work on a few test cases.

Q: Recursion ends when remainingCapacity becomes zero? The sequence of combinations to try is basically greedy.

Q: Suppose the s[i] and v[i] can be fractional, How do I avoid trying out all allowed combinations? 

====generic_factorize.py to use yield
====comboSum.cpp has a half-written memoization version, based on a recursive top-down, but not necessarily appropriate or easy to remember

====Q: insertion sort quick-n-dirty but correct
====Q[Lv] 60%: Given array of integers, every element appears three times except for one, which appears exactly once. Find that single one in a linear runtime. Could you implement it without using extra memory?

well-defined problem:)
greedy?
O(1) space probably means swapping
mutable?
-- with more space, I can use a hashtable to achieve O(N)
-- My O(N) algo {applicable for any-size integers and also other than "three"}: Pick a random pivot and partition in O(N) time and O(1) space. Also keep track how many repetitions of the pivot value (probably 3). Exclude the pivot value, count size of both partitions and discard the one whose size=3X. Repeat.

====Q[c !e L !v] 50%: Given an input string (s) and a pattern (p), implement wildcard pattern matching with support for '?' and '*'. No dot !
I think we can modify the existing solution. No need for an optimal solution

=====Q[L] 60%: Given an array nums of K integers, are there elements a, b, c in nums such that a + b + c = 0? Find all unique triplets in the array which gives the sum of zero. Doable in O(KK)
%%A: separate into (M) non-negatives and (N) negatives. M+N=K. get (NN) pairs among negatives .... and look up the sum in a pre-populated hash table of M items.
O(NN + MM), smaller than O( [N+M]^2 )
test in leetcode? No obligation
====Q[c L]: sort a list in O(N logN) but constant space? 
I think swap is way to go, but recursion stack space? iterative?

--O(1) space solution
Get a quick estimate of the median. 
Then move two pointers from far ends towards center.
Whenever med < left item,  freeze left ptr.
Whenever right item < med, freeze right ptr.
when both pointers stoped, swap them, then unfreeze both.

Now list is partitioned into two halves. Now divide and conquer. Total logN scans.

--O[N] space (not O[1]) idea
merge sort using an aux array of same size
1) divide the array into 2^j segments each up to 2 elements, rembering the (segment) boundaries.
2) sort each segment
3) merge first 2 segments and output to a new array of N but only use the first few slots
4) similarly , merge 3rd and 4th segments into the new array, using the next few slots
Once we merge all pairs, entire new array is populated and old array can be reset to 0 and usable as a blank array
Now the segment boundaries are updated and reduced by half. When segment count becomes 2, we would be on the last merge.
5) repeat Step 3

In total we visit each of N nodes logN times